from PIL import Image
import fitz
import numpy as np
import time
def summary_paragraph(client, paragraph):
    system_prompt = '''
            Báº¡n lÃ  chuyÃªn giao trong viá»‡c tÃ³m táº¯t ngáº¯n gá»n cÃ¡c vÄƒn báº£n lá»‹ch sá»­.
            HÃ£y tÃ³m táº¯t ngáº¯n gá»n Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c cung cáº¥p nhÆ°ng tuyá»‡t Ä‘á»‘i khÃ´ng Ä‘Æ°á»£c lÃ m máº¥t Ä‘i cÃ¡c thÃ´ng tin lá»‹ch sá»­ quan trá»ng.
            '''
    response = client.chat.completions.create(
            model='gpt-4o-mini',
            temperature=0,

        messages=[
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": paragraph
            }
            ]
        )
    return response.choices[0].message.content

def extract_key_word(client, summary):
    system_prompt = '''
              Báº¡n lÃ  chuyÃªn gia trong viá»‡c trÃ­ch xuáº¥t tá»« khÃ³a cho thÃ´ng tin lá»‹ch sá»­.
              HÃ£y tÃ¬m ra má»™t tá»«/cá»¥m tá»« khÃ³a cÃ³ thá»ƒ thá»ƒ hiá»‡n tá»•ng quÃ¡t ná»™i dung cá»‘t lÃµi cá»§a Ä‘oáº¡n vÄƒn.
              YÃŠU Cáº¦U:
              Chá»‰ cung cáº¥p tá»« khÃ³a, khÃ´ng Ä‘Æ°a thÃ´ng tin gÃ¬ thÃªm.
              '''
    response = client.chat.completions.create(
            model='gpt-4o-mini',
            temperature=0,

        messages=[
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": summary
            }
            ]
        )
    return response.choices[0].message.content

def pdf_to_images(documents):
    """
    Chuyá»ƒn Ä‘á»•i tá»«ng trang cá»§a file PDF sang Ä‘á»‹nh dáº¡ng PIL Image.
    Args:
        documents (fitz.Document): Äá»‘i tÆ°á»£ng PDF.
    Returns:
        list: Má»™t list cÃ¡c dictionary, má»—i dict chá»©a 'image' (PIL Image)
              vÃ  'page_number' cá»§a trang tÆ°Æ¡ng á»©ng.
    """

    doc_images = []
    for page_index, page in enumerate(documents):
        pix = page.get_pixmap(dpi=300)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        doc_images.append({
            "image": img,
            "page_index": page_index,
            "page": page
        })

    return doc_images

def detect_layout(model_detect_layout, pil_image_obj):
    """
    PhÃ¡t hiá»‡n bá»‘ cá»¥c trÃªn má»™t PIL Image báº±ng model YOLOv10.
    Args:
        model_detect_layout: Model Doclayout-yolo
        pil_image_obj (PIL.Image.Image): Äá»‘i tÆ°á»£ng PIL Image cá»§a trang.
    Returns:
        ultralytics.engine.results.Results: Äá»‘i tÆ°á»£ng káº¿t quáº£ tá»« YOLOv10 predict.
    """

    results = model_detect_layout.predict(
                  pil_image_obj,   # Image to predict
                  imgsz=1024,        # Prediction image size
                  conf=0.3,          # Confidence threshold
                  device="cpu"    # Device to use (e.g., 'cuda:0' or 'cpu')
              )
    return results[0]


def recognize_text_from_image(reader, img_array_or_pil_image):
    """
    Thá»±c hiá»‡n OCR trÃªn má»™t hÃ¬nh áº£nh (NumPy array hoáº·c PIL Image) báº±ng EasyOCR.
    Args:
        reader: easyocr.readers.ImageReader
        img_array_or_pil_image: HÃ¬nh áº£nh dÆ°á»›i dáº¡ng NumPy array (OpenCV format) hoáº·c PIL Image.
    Returns:
        list: Má»™t list cÃ¡c tuple (bbox, text, confidence) tá»« EasyOCR.
    """
    results = reader.readtext(img_array_or_pil_image, detail=0)
    return results

def recognize_text_from_pymupdf_page(docs, page_index, bbox):
    """
    TrÃ­ch xuáº¥t vÄƒn báº£n tá»« má»™t trang PyMuPDF trong má»™t vÃ¹ng (bounding box) nháº¥t Ä‘á»‹nh.

    Args:
        docs (fitz.Document): Äá»‘i tÆ°á»£ng PDF.
        page_index (int): Index cá»§a trang trong PDF.
        bbox (list hoáº·c tuple): Bounding box dÆ°á»›i dáº¡ng [x1, y1, x2, y2], Ä‘Ã¢y lÃ  tá»a Ä‘á»™ hÃ¬nh áº£nh

    Returns:
        str: VÄƒn báº£n Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« vÃ¹ng Ä‘Ã£ cho. Tráº£ vá» chuá»—i rá»—ng náº¿u khÃ´ng tÃ¬m tháº¥y text.
    """
    try:

        # chuyá»ƒn sang tá»a Ä‘á»™ hÃ¬nh áº£nh sang tá»a Ä‘á»™ PDF
        # 300 DPI = 300/72 = 4.167 pixels per point

        scale = 300/72
        # Táº¡o má»™t fitz.Rect tá»« bounding box
        x1, y1, x2, y2 = [coord / scale for coord in bbox]

        # Táº¡o clip rect vÃ  trÃ­ch xuáº¥t text
        clip_rect = fitz.Rect(x1, y1, x2, y2)
        pymupdf_page = docs[page_index]
        block = pymupdf_page.get_text('blocks',clip= clip_rect)

        text = block[0][4]
        text = text.replace('.\n','.#')
        text = text.replace('\n',' ')

        return  text

    except Exception as e:
        print(f"  âŒ Lá»—i khi trÃ­ch xuáº¥t text tá»« PyMuPDF: {str(e)}")
        return "" # Tráº£ vá» chuá»—i rá»—ng náº¿u cÃ³ lá»—i


def process_pdf_page(docs, model_detect_layout,reader, pdf_page_data, continue_index):
    """
    Xá»­ lÃ½ má»™t trang PDF: phÃ¡t hiá»‡n bá»‘ cá»¥c vÃ  nháº­n dáº¡ng vÄƒn báº£n.
    Args:
        model_detect_layout: model Doclayout_yolo
        pdf_page_data (dict): Dictionary chá»©a 'image' (PIL Image) vÃ  'page_index'.
        continue_index (int): Index tiáº¿p tá»¥c tá»« láº§n xá»­ lÃ½ trÆ°á»›c
    Returns:
        tuple: (continue_index, processed_paragraphs, page_results)
    """
    page_index = pdf_page_data["page_index"]
    pil_image = pdf_page_data["image"]

    print(f"\n--- Xá»­ lÃ½ trang: {page_index} ---")

    # 1. PhÃ¡t hiá»‡n bá»‘ cá»¥c
    layout_results = detect_layout(model_detect_layout, pil_image)
    processed_paragraphs = []

    # Kiá»ƒm tra xem cÃ³ boxes khÃ´ng
    if not (hasattr(layout_results, 'boxes') and layout_results.boxes):
        print("    KhÃ´ng tÃ¬m tháº¥y Ä‘á»‘i tÆ°á»£ng bá»‘ cá»¥c nÃ o.")
        return continue_index, processed_paragraphs

    # 2. Xá»­ lÃ½ tá»«ng box
    for i, box in enumerate(layout_results.boxes):
        bbox = box.xyxy[0].tolist()
        x1, y1, x2, y2 = map(int, bbox)
        label = model_detect_layout.names[int(box.cls[0])]
        score = box.conf[0].item()
        # Chá»‰ xá»­ lÃ½ box khÃ´ng pháº£i abandon
        if label == 'abandon':
            continue
        # Chá»‰ xá»­ lÃ½ box cÃ³ confidence >= threshold
        if score < 0.4:
            continue

        continue_index += 1

        try:
            # Cáº¯t áº£nh theo bbox
            image_cut = pil_image.crop((x1, y1, x2, y2))
            img_np = np.array(image_cut)

            # 4. Nháº­n dáº¡ng vÄƒn báº£n
            start_time = time.time()
            recognized_text_results = recognize_text_from_pymupdf_page(docs, page_index, bbox)
            end_time = time.time()
            print(f"      â±ï¸  Thá»i gian trÃ­ch text: {end_time - start_time:.2f} giÃ¢y")
            if recognized_text_results == "":
                recognized_text_results = recognize_text_from_image(reader, img_np)
                recognized_text_results = ' '.join(recognized_text_results)
            print(f"      âœ… Nháº­n dáº¡ng Ä‘Æ°á»£c {recognized_text_results} text")
            # 5. Táº¡o thÃ´ng tin paragraph
            if recognized_text_results:
                paragraph_info = {
                    'type': label,
                    'full_text': recognized_text_results,
                    'page_index': page_index,
                    'parent_index': -1,
                    'index': continue_index,
                    'is_title': label == 'title'
                }

                processed_paragraphs.append(paragraph_info)

            else:
                print(f"      âš  KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c text")
                continue_index -= 1  # Rollback index náº¿u khÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c

        except Exception as e:
            print(f"      âŒ Lá»—i khi xá»­ lÃ½ box: {str(e)}")
            continue_index -= 1  # Rollback index náº¿u cÃ³ lá»—i
    e_time = time.time()
    print(f"\n  >>> HoÃ n thÃ nh xá»­ lÃ½ trang {page_index}: {len(processed_paragraphs)} paragraphs")
    return continue_index, processed_paragraphs


def process_full_pdf(model_detect_layout, reader, pdf_path):
    """
    Xá»­ lÃ½ toÃ n bá»™ file PDF: chuyá»ƒn Ä‘á»•i, phÃ¡t hiá»‡n bá»‘ cá»¥c vÃ  nháº­n dáº¡ng vÄƒn báº£n tá»«ng trang.
    Args:
        pdf_path (str): ÄÆ°á»ng dáº«n Ä‘áº¿n file PDF.
    Returns:
        dict: Dictionary chá»©a táº¥t cáº£ káº¿t quáº£ xá»­ lÃ½ vÃ  thá»‘ng kÃª
    """
    print(f"\nğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ PDF: {pdf_path}")
    documents = fitz.open(pdf_path)
    # Chuyá»ƒn Ä‘á»•i PDF thÃ nh áº£nh
    start_time = time.time()
    all_page_images = pdf_to_images(documents)
    end_time = time.time()
    total_pages = len(all_page_images)
    print(f"ğŸ“„ Tá»•ng sá»‘ trang: {total_pages}")
    print(f"â±ï¸  Thá»i gian chuyá»ƒn Ä‘á»•i: {end_time - start_time:.2f} giÃ¢y")
    # Khá»Ÿi táº¡o káº¿t quáº£

    all_paragraphs = []
    continue_index = 0

    # Xá»­ lÃ½ tá»«ng trang
    for i, page_data in enumerate(all_page_images, 1):
        print(f"\nğŸ“– Äang xá»­ lÃ½ trang {i}/{total_pages}...")

        try:
            # Xá»­ lÃ½ trang vÃ  nháº­n káº¿t quáº£
            start_time = time.time()
            continue_index, page_paragraphs = process_pdf_page(documents, model_detect_layout,reader, page_data, continue_index)
            end_time = time.time()
            print(f"â±ï¸  Thá»i gian detect vÃ  trÃ­ch text trang {i}: {end_time - start_time:.2f} giÃ¢y")
            # ThÃªm paragraphs vÃ o danh sÃ¡ch tá»•ng
            all_paragraphs.extend(page_paragraphs)

            print(f"âœ… HoÃ n thÃ nh trang {i}: {len(page_paragraphs)} paragraphs")

        except Exception as e:
            print(f"âŒ Lá»—i khi xá»­ lÃ½ trang {i}: {str(e)}")


    # Táº¡o thá»‘ng kÃª tá»•ng quan
    total_paragraphs = len(all_paragraphs)
    return {
        "pdf_path": pdf_path,
        "total_pages": total_pages,
        "total_paragraphs": total_paragraphs,
        "all_paragraphs": all_paragraphs,
    }

def merge_short_paragraphs(pdf_result_all_paragraphs, n_word=200):
    """
    Gá»™p cÃ¡c Ä‘oáº¡n vÄƒn báº£n ngáº¯n (dÆ°á»›i n_word tá»«) vá»›i Ä‘oáº¡n vÄƒn báº£n káº¿ tiáº¿p nÃ³.
    HÃ m sáº½ thay Ä‘á»•i trá»±c tiáº¿p list Ä‘áº§u vÃ o vÃ  giáº£m sá»‘ lÆ°á»£ng pháº§n tá»­.

    Args:
        pdf_result_all_paragraphs (list): List cÃ¡c dictionary, má»—i dictionary lÃ  má»™t Ä‘oáº¡n.
                                          Má»—i dict pháº£i cÃ³ key 'full_text'.
        n_word (int): NgÆ°á»¡ng sá»‘ tá»«. Náº¿u Ä‘oáº¡n cÃ³ Ã­t hÆ¡n n_word tá»«, nÃ³ sáº½ Ä‘Æ°á»£c gá»™p.

    Returns:
        list: List Ä‘Ã£ Ä‘Æ°á»£c gá»™p. ÄÃ¢y cÅ©ng chÃ­nh lÃ  list Ä‘Ã£ Ä‘Æ°á»£c sá»­a Ä‘á»•i tá»« Ä‘áº§u vÃ o.
    """
    # Táº¡o má»™t báº£n sao Ä‘á»ƒ khÃ´ng lÃ m thay Ä‘á»•i list gá»‘c bÃªn ngoÃ i hÃ m náº¿u khÃ´ng muá»‘n
    paragraphs = list(pdf_result_all_paragraphs)
    i = 0
    # DÃ¹ng 'while' vÃ¬ Ä‘á»™ dÃ i cá»§a list sáº½ thay Ä‘á»•i trong quÃ¡ trÃ¬nh láº·p
    while i < len(paragraphs) - 1:
        current_paragraph = paragraphs[i]

        # Äáº¿m sá»‘ tá»« trong Ä‘oáº¡n hiá»‡n táº¡i
        word_count = len(current_paragraph.get('full_text', '').split())

        # Náº¿u Ä‘oáº¡n hiá»‡n táº¡i ngáº¯n, gá»™p nÃ³ vá»›i Ä‘oáº¡n káº¿ tiáº¿p
        if word_count < n_word:
            next_paragraph = paragraphs[i + 1]

            # Gá»™p text cá»§a Ä‘oáº¡n sau vÃ o Ä‘oáº¡n hiá»‡n táº¡i
            current_paragraph['full_text'] += " " + next_paragraph.get('full_text', '')

            # XÃ³a Ä‘oáº¡n káº¿ tiáº¿p khá»i list sau khi Ä‘Ã£ gá»™p
            paragraphs.pop(i + 1)

            # QUAN TRá»ŒNG: KhÃ´ng tÄƒng 'i'
            # Giá»¯ nguyÃªn 'i' Ä‘á»ƒ kiá»ƒm tra láº¡i chÃ­nh Ä‘oáº¡n vá»«a Ä‘Æ°á»£c gá»™p
            # vÃ¬ nÃ³ cÃ³ thá»ƒ váº«n cÃ²n ngáº¯n vÃ  cáº§n gá»™p tiáº¿p vá»›i Ä‘oáº¡n sau ná»¯a.
        else:
            # Náº¿u Ä‘oáº¡n hiá»‡n táº¡i Ä‘Ã£ Ä‘á»§ dÃ i, chuyá»ƒn sang kiá»ƒm tra Ä‘oáº¡n tiáº¿p theo
            i += 1

    return paragraphs

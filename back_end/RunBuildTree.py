from ParagraphClusterer import *
from ClusteringTreeBuilder import *
from PDF_Processor import summary_paragraph, extract_key_word
import time
from FindOptimalK import get_optimal_k_with_final_merge_logic
def run_clustering_with_tree_building(client, model_embedding, list_node , clustering_strategy='adaptive'):
    """
    Cháº¡y phÃ¢n cá»¥m vÃ  xÃ¢y dá»±ng cÃ¢y Ä‘á»“ng thá»i
    """
    # Khá»Ÿi táº¡o cÃ¡c Ä‘á»‘i tÆ°á»£ng
    clusterer = ParagraphClusterer(model_embedding)
    tree_builder = ClusteringTreeBuilder()

    # Dá»¯ liá»‡u ban Ä‘áº§u
    initial_paragraphs = [paragraph['full_text'] for paragraph in list_node]
    s_time = time.time()
    initial_summarized_paragraphs = []
    for full_paragraph in initial_paragraphs:
        summarized_paragraph = summary_paragraph(client, full_paragraph )
        initial_summarized_paragraphs.append(summarized_paragraph)

    list_paragraphs = initial_summarized_paragraphs.copy()
    list_keywords = [extract_key_word(client, paragraph) for paragraph in initial_paragraphs]
    e_time = time.time()
    print(f"Thá»i gian summarize vÃ  tÃ¡ch key word: {e_time - s_time}s")

    print(f"ğŸš€ Báº®T Äáº¦U PHÃ‚N Cá»¤M VÃ€ XÃ‚Y Dá»°NG CÃ‚Y")
    print(f"Sá»‘ Ä‘oáº¡n vÄƒn ban Ä‘áº§u: {len(initial_paragraphs)}")

    # ThÃªm cÃ¡c Ä‘oáº¡n vÄƒn ban Ä‘áº§u vÃ o cÃ¢y, cÃ¡c nÃºt lÃ¡
    current_indices = tree_builder.add_initial_paragraphs(client, paragraphs = initial_summarized_paragraphs, keywords=list_keywords)

    round_count = 1

    while len(list_paragraphs) > 1:
        print(f"\n{'='*60}")
        print(f"--- VÃ’NG {round_count} | Sá»‘ Ä‘oáº¡n hiá»‡n táº¡i: {len(list_paragraphs)} ---")
        print(f"{'='*60}")

        # NhÃºng cÃ¡c Ä‘oáº¡n vÄƒn thÃ nh vector
        clusterer.embed_paragraphs(list_paragraphs, list_keywords)

        # Láº¥y sá»‘ cá»¥m tá»‘i Æ°u
        optimal_k = get_optimal_k_with_final_merge_logic(
            list_paragraphs,
            clusterer,
            clustering_strategy
        )

        print(f"\nğŸ¯ Sá»‘ cá»¥m Ä‘Æ°á»£c chá»n: {optimal_k}")

        # Thá»±c hiá»‡n phÃ¢n cá»¥m
        if clusterer.perform_kmeans_clustering(optimal_k):
            cluster_info = clusterer.get_cluster_info()

            # ThÃªm vÃ o cÃ¢y
            new_indices = tree_builder.add_cluster_round(
                cluster_info,
                round_count,
                current_indices
            )

            # Cáº­p nháº­t cho vÃ²ng láº·p tiáº¿p theo
            previous_count = len(list_paragraphs)
            list_paragraphs = [cluster['represent'] for cluster in cluster_info]
            list_keywords = [cluster['keyword'] for cluster in cluster_info]

            current_indices = new_indices
            current_count = len(list_paragraphs)

            print(f"\nğŸ“‰ Giáº£m tá»« {previous_count} xuá»‘ng {current_count} Ä‘oáº¡n")

            # Kiá»ƒm tra Ä‘iá»u kiá»‡n dá»«ng
            if current_count == 1:
                print(f"\nğŸ‰ Äáº T ÄÆ¯á»¢C Má»¤C TIÃŠU: Gom thÃ nh 1 Ä‘oáº¡n cuá»‘i cÃ¹ng!")
                break

        else:
            print("\nâŒ PhÃ¢n cá»¥m khÃ´ng thÃ nh cÃ´ng - Dá»«ng quÃ¡ trÃ¬nh")
            break

        round_count += 1

        # Báº£o vá»‡ trÃ¡nh vÃ²ng láº·p vÃ´ háº¡n
        if round_count > 20:
            print("\nâš ï¸ ÄÃ£ cháº¡y quÃ¡ 20 vÃ²ng - Dá»«ng Ä‘á»ƒ trÃ¡nh vÃ´ háº¡n")
            break

    # # Hiá»ƒn thá»‹ káº¿t quáº£
    # tree_builder.print_tree_summary()
    # tree_builder.visualize_tree_structure()
    #
    # # Xuáº¥t file
    # # json_file = tree_builder.export_to_json()

    return {
        'tree': tree_builder.get_tree_structure(),
        'tree_builder': tree_builder
    }
